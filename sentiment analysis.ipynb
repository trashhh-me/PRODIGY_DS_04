{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d46ee5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ff62ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06d0654b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7222557095974818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.83      0.56      0.67      2604\n",
      "    Negative       0.68      0.85      0.76      4512\n",
      "     Neutral       0.80      0.60      0.69      3608\n",
      "    Positive       0.69      0.79      0.74      4207\n",
      "\n",
      "    accuracy                           0.72     14931\n",
      "   macro avg       0.75      0.70      0.71     14931\n",
      "weighted avg       0.74      0.72      0.72     14931\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "data = pd.read_excel(\"C:/Users/DELL/Desktop/training.xlsx\")\n",
    "\n",
    "# Preprocessing the text data\n",
    "def preprocess_text(text):\n",
    "    if isinstance(text, str):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'@\\S+', '', text)\n",
    "        text = re.sub(r'#\\S+', '', text) \n",
    "        text = re.sub(r'http\\S+', '', text)  \n",
    "        text = re.sub(r'[^a-zA-Z\\s]', '', text) \n",
    "        text = ' '.join(word for word in text.split() if word not in stopwords.words('english'))  \n",
    "        text = ''  \n",
    "    return text\n",
    "\n",
    "data['comment'] = data['comment'].apply(preprocess_text)\n",
    "X = data['comment']\n",
    "y = data['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1398cbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conclusions:\n",
      "The model achieved reasonable accuracy, indicating that it can classify sentiment to some extent.\n",
      "The model performs well in classifying positive sentiment.\n",
      "The model performs well in classifying neutral sentiment.\n",
      "The model performs well in classifying negative sentiment.\n"
     ]
    }
   ],
   "source": [
    "print(\"Conclusions:\")\n",
    "if accuracy > 0.5:\n",
    "    print(\"The model achieved reasonable accuracy, indicating that it can classify sentiment to some extent.\")\n",
    "else:\n",
    "    print(\"The model's accuracy is relatively low, and it may not perform well in sentiment classification tasks.\")\n",
    "positive_f1 = report.split()[13]  # F1-score for 'Positive' class\n",
    "neutral_f1 = report.split()[22]   # F1-score for 'Neutral' class\n",
    "negative_f1 = report.split()[31]  # F1-score for 'Negative' class\n",
    "\n",
    "if float(positive_f1) > 0.5:\n",
    "    print(\"The model performs well in classifying positive sentiment.\")\n",
    "else:\n",
    "    print(\"The model struggles with classifying positive sentiment.\")\n",
    "\n",
    "if float(neutral_f1) > 0.5:\n",
    "    print(\"The model performs well in classifying neutral sentiment.\")\n",
    "else:\n",
    "    print(\"The model struggles with classifying neutral sentiment.\")\n",
    "\n",
    "if float(negative_f1) > 0.5:\n",
    "    print(\"The model performs well in classifying negative sentiment.\")\n",
    "else:\n",
    "    print(\"The model struggles with classifying negative sentiment.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6139e27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
